# ğŸ“‚ Project Structure

## Overview

```
recommendation-system/
â”œâ”€â”€ ğŸ“± Frontend
â”‚   â””â”€â”€ index.html                   # Web UI (chat, search, memory, recommendations)
â”‚
â”œâ”€â”€ ğŸš€ Backend
â”‚   â”œâ”€â”€ main.py                      # FastAPI application & API endpoints
â”‚   â”œâ”€â”€ recommendation_engine.py     # Core recommendation algorithms
â”‚   â”‚
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ database.py              # Database connections (PostgreSQL, MongoDB)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py               # Data models & API request/response schemas
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ chatbot.py               # AI chat & NLP query processing
â”‚       â”œâ”€â”€ search_engine.py         # Intelligent product search
â”‚       â”œâ”€â”€ memory.py                # Conversation memory (Redis + MongoDB)
â”‚       â”œâ”€â”€ collaborative_filtering.py  # Recommendation algorithms
â”‚       â””â”€â”€ data_loader.py           # Data loading utilities
â”‚
â”œâ”€â”€ ğŸ³ Deployment
â”‚   â”œâ”€â”€ Dockerfile                   # Container image definition
â”‚   â”œâ”€â”€ docker-compose.yml           # Multi-service orchestration
â”‚   â”œâ”€â”€ .dockerignore                # Docker build exclusions
â”‚   â”œâ”€â”€ deploy-ecr.sh                # AWS ECR deployment script
â”‚   â”œâ”€â”€ setup-aws-infrastructure.sh  # AWS resource creation
â”‚   â””â”€â”€ ecs-task-definition.json    # ECS Fargate configuration
â”‚
â”œâ”€â”€ ğŸ§ª Testing & Examples
â”‚   â”œâ”€â”€ example.py                   # Sample data & DB initialization
â”‚   â”œâ”€â”€ test_chatbot.py             # Chatbot feature tests
â”‚   â”œâ”€â”€ test_memory.py              # Memory system tests
â”‚   â””â”€â”€ test_api.py                 # API endpoint tests
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ .env                        # Environment variables (not in git)
â”‚   â”œâ”€â”€ .env.example                # Environment template
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â””â”€â”€ .gitignore                  # Git exclusions
â”‚
â”œâ”€â”€ ğŸ› ï¸ Setup & Utilities
â”‚   â””â”€â”€ setup.sh                    # Complete system setup script
â”‚
â””â”€â”€ ğŸ“– Documentation
    â”œâ”€â”€ README.md                    # Main documentation & feature overview
    â”œâ”€â”€ GETTING_STARTED.md          # Setup guide (Docker, Local, AWS)
    â”œâ”€â”€ MEMORY_MANAGEMENT.md        # Memory system architecture
    â”œâ”€â”€ DOCKER_GUIDE.md             # Docker usage & commands
    â””â”€â”€ AWS_DEPLOYMENT.md           # Production deployment guide
```

---

## ğŸ“± Frontend

### `index.html` (800+ lines)
- **Purpose**: Full-featured web interface
- **Features**: 
  - ğŸ’¬ Chat tab with AI assistant
  - ğŸ” Product search interface
  - ğŸ§  Memory management (view history, preferences)
  - ğŸ¯ Personalized recommendations
  - ğŸ“Š Real-time statistics
- **Tech**: Vanilla JavaScript, modern CSS with gradients
- **Usage**: Open directly in browser or via `http://localhost:8000/index.html`

---

## ğŸš€ Backend

### `main.py` (400+ lines)
- **Purpose**: FastAPI application & API route definitions
- **Key Endpoints**:
  - `POST /chat` - AI-powered chat
  - `POST /search` - Product search
  - `GET /recommend/user/{id}` - User recommendations
  - `GET /recommend/item/{id}` - Similar products
  - `GET /memory/*` - Memory management
- **Startup**: Initializes databases, loads data, starts memory services

### `recommendation_engine.py` (300+ lines)
- **Purpose**: Core recommendation logic
- **Algorithms**:
  - User-based collaborative filtering
  - Item-based collaborative filtering
  - Similarity computation (cosine similarity)
- **Data**: Manages user-item matrices, similarity matrices

### Services

#### `services/chatbot.py` (280+ lines)
- **Purpose**: Natural language processing & chat logic
- **Key Functions**:
  - `process_query()` - Analyze user intent with OpenAI
  - `generate_response()` - Create conversational responses
- **Features**: Intent extraction, category detection, price range parsing

#### `services/search_engine.py` (350+ lines)
- **Purpose**: Intelligent product search combining NLP + recommendations
- **Key Functions**:
  - `search()` - Main search orchestration
  - `filter_products()` - Apply category, price, brand filters
  - `rank_results()` - Personalization scoring
- **Scoring**: Combines relevance + personalization (70/30 split)

#### `services/memory.py` (340+ lines)
- **Purpose**: Two-tier conversation memory system
- **Key Functions**:
  - `add_message()` - Store in Redis + MongoDB
  - `get_conversation_context()` - Load recent messages
  - `get_user_preferences()` - Extract categories, brands, keywords
- **Storage**: 
  - Short-term: Redis (1 hour TTL)
  - Long-term: MongoDB (persistent)

#### `services/collaborative_filtering.py` (150+ lines)
- **Purpose**: Recommendation algorithm implementations
- **Methods**:
  - `get_recommendations()` - User or item-based CF
  - `get_similar_users()` - Find users with similar taste
  - `get_similar_items()` - Find similar products
- **Tech**: Scikit-learn cosine similarity, sparse matrices

#### `services/data_loader.py` (100+ lines)
- **Purpose**: Load data from databases
- **Functions**:
  - `load_users()` - From PostgreSQL
  - `load_products()` - From PostgreSQL
  - `load_purchase_history()` - From MongoDB

### Configuration

#### `config/database.py` (80+ lines)
- **Purpose**: Database connection management
- **Connections**:
  - SQLAlchemy engine (PostgreSQL)
  - MongoDB client
  - Redis client (optional)
- **Features**: Connection pooling, error handling

### Models

#### `models/schemas.py` (200+ lines)
- **Purpose**: Data models for database & API
- **SQLAlchemy Models**:
  - `User` - User profiles
  - `Product` - Product catalog
- **Pydantic Models**:
  - `ChatRequest/Response` - Chat API
  - `SearchRequest/Response` - Search API
  - `RecommendationResponse` - Recommendation API
  - `MemoryResponse` - Memory API

---

## ğŸ³ Deployment

### Docker Files

#### `Dockerfile` (35 lines)
- **Base**: python:3.11-slim
- **Layers**:
  1. System dependencies (gcc, postgresql-client)
  2. Python packages
  3. Application code
- **Health Check**: curl localhost:8000/health
- **Port**: 8000

#### `docker-compose.yml` (120 lines)
- **Services**:
  - `app` - FastAPI application
  - `postgres` - PostgreSQL 14
  - `mongodb` - MongoDB 7
  - `redis` - Redis 7
- **Features**: Health checks, volume persistence, networking

### AWS Deployment Scripts

#### `deploy-ecr.sh` (100 lines)
- **Purpose**: Push Docker image to AWS ECR
- **Steps**:
  1. Validate AWS CLI
  2. Create/verify ECR repository
  3. Authenticate Docker to ECR
  4. Build, tag, push image
- **Output**: ECR image URI

#### `setup-aws-infrastructure.sh` (200 lines)
- **Purpose**: Create AWS resources
- **Creates**:
  - CloudWatch log groups
  - Secrets Manager secret (OpenAI key)
  - VPC & security groups
  - ECS cluster
  - IAM roles
- **Usage**: Run before deploying ECS service

#### `ecs-task-definition.json` (120 lines)
- **Purpose**: ECS Fargate task configuration
- **Specs**: 1 vCPU, 2GB RAM
- **Environment**: Database URLs, API keys
- **Logging**: CloudWatch logs

---

## ğŸ§ª Testing & Examples

### `example.py` (200 lines)
- **Purpose**: Create sample data & initialize database
- **Creates**:
  - 10 users with profiles
  - 15 products across categories
  - 38 realistic purchases
- **Demo**: Shows recommendation engine in action

### `test_chatbot.py` (150 lines)
- **Tests**:
  - Chat with various query types
  - Search functionality
  - Conversation suggestions
  - Intent detection

### `test_memory.py` (120 lines)
- **Tests**:
  - Session management
  - Conversation history
  - Preference extraction
  - Context awareness

### `test_api.py` (100 lines)
- **Tests**:
  - All API endpoints
  - Error handling
  - Response validation

---

## âš™ï¸ Configuration

### `.env` (not in git)
```env
# PostgreSQL
SQL_DATABASE_URL=postgresql://user@localhost:5432/recommendation_db

# MongoDB
MONGO_URI=mongodb://localhost:27017/
MONGO_DATABASE=recommendation_db

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# OpenAI
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Memory
SESSION_TTL=3600
MAX_CONTEXT_MESSAGES=10
```

### `requirements.txt` (25 packages)
- **Web**: fastapi, uvicorn, python-multipart
- **Database**: sqlalchemy, psycopg2-binary, pymongo, redis
- **AI/ML**: openai, scikit-learn, pandas, numpy
- **Utils**: python-dotenv, pydantic

---

## ğŸ› ï¸ Setup Scripts

### `setup.sh` (300 lines)
- **Purpose**: One-command complete setup
- **Installs**:
  - PostgreSQL (required)
  - MongoDB (optional)
  - Redis (optional)
- **Configures**:
  - Creates database
  - Sets up .env file
  - Installs Python packages
  - Loads sample data
- **OS Support**: macOS, Linux

---

## ğŸ“– Documentation

### `README.md` (400 lines)
- **Sections**:
  - Features overview
  - Quick start (3 options)
  - API reference
  - Tech stack
  - Configuration

### `GETTING_STARTED.md` (700 lines)
- **Complete setup guide**:
  - Option 1: Docker (recommended)
  - Option 2: Local development
  - Option 3: AWS cloud
- **Includes**: Troubleshooting, sample data, testing

### `MEMORY_MANAGEMENT.md` (400 lines)
- **Deep dive on memory system**:
  - Architecture (Redis + MongoDB)
  - API endpoints
  - Configuration
  - Usage examples

### `DOCKER_GUIDE.md` (500 lines)
- **Docker usage**:
  - docker-compose commands
  - Development workflow
  - Troubleshooting
  - Production optimization

### `AWS_DEPLOYMENT.md` (400 lines)
- **Production deployment**:
  - Complete AWS setup
  - Cost estimation
  - Monitoring & logging
  - CI/CD pipeline examples

---

## ğŸ” Finding Code

### Need to modify...

**Chat behavior?**
â†’ `services/chatbot.py`

**Search logic?**
â†’ `services/search_engine.py`

**Recommendations?**
â†’ `recommendation_engine.py` or `services/collaborative_filtering.py`

**Memory management?**
â†’ `services/memory.py`

**API endpoints?**
â†’ `main.py`

**Database models?**
â†’ `models/schemas.py`

**UI appearance?**
â†’ `index.html` (CSS in `<style>` tag)

**Docker configuration?**
â†’ `docker-compose.yml` or `Dockerfile`

**AWS deployment?**
â†’ `deploy-ecr.sh`, `setup-aws-infrastructure.sh`, `ecs-task-definition.json`

---

## ğŸ“Š Code Statistics

| Component | Files | Lines of Code |
|-----------|-------|---------------|
| Backend (Python) | 10 | ~2,500 |
| Frontend (HTML/JS) | 1 | ~800 |
| Deployment | 5 | ~600 |
| Tests | 3 | ~400 |
| Documentation | 5 | ~2,500 |
| **Total** | **24** | **~6,800** |

---

## ğŸš€ Quick Navigation

- **Start here**: [GETTING_STARTED.md](GETTING_STARTED.md)
- **Understand features**: [README.md](README.md)
- **Deploy with Docker**: [DOCKER_GUIDE.md](DOCKER_GUIDE.md)
- **Deploy to AWS**: [AWS_DEPLOYMENT.md](AWS_DEPLOYMENT.md)
- **Memory system**: [MEMORY_MANAGEMENT.md](MEMORY_MANAGEMENT.md)
- **Code structure**: You're reading it! ğŸ“–
