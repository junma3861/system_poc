# GitHub Copilot Instructions for Video Recommendation System

Follow all guidelines in `claude.md`. This file ensures Copilot provides consistent, project-aligned suggestions.

## Code Style & Conventions

### Python Style
- Follow **PEP 8** style guide
- **Type hints** required for all function parameters and return values
- **Maximum line length**: 88 characters (Black formatter default)
- **Docstrings** for all public modules, functions, classes, and methods
  - Use Google or NumPy style
  - Example: `"""Brief description. Longer description if needed."""`

### Naming Conventions
- **Variables/Functions**: `snake_case`
- **Classes**: `PascalCase`
- **Constants**: `UPPER_SNAKE_CASE`
- **Private members**: `_leading_underscore`

### Import Order
Organize imports in this order (separate groups with blank lines):
1. Standard library imports
2. Related third-party imports
3. Local application/library specific imports

Example:
```python
import os
from pathlib import Path
from typing import List

from psycopg import Connection, connect
from pgvector.psycopg import Vector, register_vector

from data_platform.data_model.user import UserProfile
```

## Project Structure
```
├── src/                    # Source code
├── tests/                  # Test files (pytest)
├── data/                   # Data files
├── config/                 # Configuration files
│   └── db/                 # Postgres/pgvector init scripts
├── docker-compose.yml      # Local pgvector + redis + dynamodb stack
├── environment.yml         # Conda environment file
├── .volumes/postgres/      # Postgres data
├── .volumes/redis/         # Redis data
├── .volumes/dynamodb/      # DynamoDB Local data
└── claude.md              # Project guidelines
```

## Database Setup

### Starting the Database
```bash
# Start PostgreSQL with pgvector
docker-compose up -d pgvector

# Check status
docker-compose ps

# View logs
docker-compose logs -f pgvector
```

### Connection String
```
postgresql://video_admin:video_admin@localhost:5432/video_rec_dev
```

### Starting Redis and DynamoDB Local
```bash
# Start cache and event store
docker-compose up -d redis dynamodb

# Check status
docker-compose ps

# DynamoDB Local endpoint
export AWS_ACCESS_KEY_ID=local
export AWS_SECRET_ACCESS_KEY=local
export AWS_REGION=us-east-1
export DYNAMODB_ENDPOINT=http://localhost:8001
```

### Environment
```bash
# Create and activate conda environment
conda env create -f environment.yml
conda activate video-rec

# Or just activate if already exists
conda activate video-rec
```

## Testing

### Running Tests
```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_db_connection.py -v
pytest tests/test_interaction_store.py -v

# Run with coverage
pytest tests/ --cov=src/

# Run with conda environment
conda run -n video-rec pytest tests/ -v
```

### Test Requirements
- Write unit tests for all new functionality
- Aim for high test coverage on critical paths
- Use fixtures for common test setup
- Place all tests in `tests/` directory
- Tests must pass before committing code

## Code Quality

### Formatting & Linting
```bash
# Format code with Black
black .

# Sort imports
isort .

# Lint code
flake8 .

# Type checking
mypy src/
```

### Error Handling
- Use specific exception types over generic `Exception`
- Always include meaningful error messages
- Use context managers for resource management
- Example:
  ```python
  @contextmanager
  def db_connection(database_url: str) -> Iterable[Connection]:
      """Yield a Postgres connection with pgvector support registered."""
      conn = connect(database_url, autocommit=True)
      try:
          register_vector(conn)
          yield conn
      finally:
          conn.close()
  ```

## Key Dependencies

- **Python**: 3.10+
- **Package Manager**: conda
- **Database**: PostgreSQL 17 with pgvector
- **Cache**: Redis (local) / ElastiCache (prod)
- **Event Store**: DynamoDB Local (prod: DynamoDB)
- **Client libs**: psycopg (3.1+), pgvector, redis (py), boto3
- **Data Validation**: pydantic (2.0.0+)
- **Testing**: pytest (7.4.0+)
- **Formatting**: black, isort, flake8
- **Type Checking**: mypy

## Common Development Tasks

| Task | Command |
|------|---------|
| Start environment | `conda activate video-rec` |
| Start database | `docker-compose up -d pgvector` |
| Start cache + DynamoDB | `docker-compose up -d redis dynamodb` |
| Run tests | `pytest tests/ -v` |
| Format code | `black .` && `isort .` |
| Check types | `mypy src/` |
| Lint code | `flake8 .` |
| Stop services | `docker-compose down` |
| Reset data (dev) | `docker-compose down -v && rm -rf .volumes/postgres .volumes/redis .volumes/dynamodb` |

## Best Practices

1. **Prefer composition over inheritance**
2. **Write code that is easy to test and maintain**
3. **Keep dependencies minimal and well-documented**
4. **Use meaningful variable and function names**
5. **Write clear docstrings explaining what, why, and how**
6. **Use type hints for better IDE support and type safety**
7. **Write small, focused functions and classes**
8. **Test critical paths thoroughly**
9. **Document configuration options and environment variables**
10. **Keep README.md updated with setup and usage instructions**

## Data Model

The project uses Pydantic models for data validation:
- **UserProfile**: User data with embeddings and engagement metrics
- **VideoAsset**: Video metadata with vector embeddings
- All models include proper type hints and validation

See `src/data_platform/data_model/` for implementations.

## Notes

- Always ensure imports work correctly (test imports when creating new modules)
- When adding new dependencies, update `environment.yml`
- Embedding vectors default to 768 dimensions (configurable via `EMBEDDING_DIM`)
- Database persists data in `.volumes/postgres/` (git-ignored)
- Use `autocommit=True` for psycopg connections when appropriate
